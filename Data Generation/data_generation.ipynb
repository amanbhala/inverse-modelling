{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import asyncio\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat  # Import loadmat\n",
    "# import matlab.engine\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from scipy.interpolate import griddata\n",
    "from scipy.interpolate import interp2d, RegularGridInterpolator\n",
    "from scipy.linalg import cholesky\n",
    "import sampyl as smp\n",
    "import sys\n",
    "import multiprocessing as mp\n",
    "from numba import jit\n",
    "import csv\n",
    "from matplotlib.colors import ListedColormap\n",
    "# Set print options to increase precision\n",
    "np.set_printoptions(precision=20, suppress=False, formatter={'complexfloat': '{: 0.4f}'.format})\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from scipy.io import savemat\n",
    "import gstools as gs\n",
    "from gstools import SRF, Gaussian\n",
    "from gstools.random import MasterRNG\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_array_3bingham_distributions(num):\n",
    "    # structured field with a size of 100x100 and a grid-size of 1x1\n",
    "    x = y = range(26)\n",
    "\n",
    "    model = Gaussian(dim=2, var=1, len_scale=500)\n",
    "    srf = SRF(model)\n",
    "    grf_array = srf.structured([x, y])\n",
    "    # srf1.plot()\n",
    "    # print(grf_array.shape)a\n",
    "    # plt.imshow(grf_array)\n",
    "    # plt.colorbar()  # To show the color scale\n",
    "    # plt.savefig(\"data/grfplot_{}.png\".format(num))\n",
    "    # plt.close()\n",
    "    # plt.show()\n",
    "\n",
    "    # Dynamically generate random values for percentiles\n",
    "    percentile1 = np.random.uniform(20, 50)  # Random percentile between 20 and 50\n",
    "    percentile2 = np.random.uniform(51, 90)  # Random percentile between 51 and 90\n",
    "    minimum1 = grf_array.min()\n",
    "    maximum1 = grf_array.max()\n",
    "\n",
    "    # Calculate the thresholds based on the dynamically chosen percentiles\n",
    "    threshold1 = np.percentile(grf_array, percentile1)\n",
    "    threshold2 = np.percentile(grf_array, percentile2)\n",
    "\n",
    "    # print(f\"Minimum: {minimum1}\")\n",
    "    # print(f\"Maximum: {maximum1}\")\n",
    "    print(f\"30th Percentile (Dynamic): {percentile1}\")\n",
    "    print(f\"50th Percentile (Dynamic): {percentile2}\")\n",
    "\n",
    "    resultant_array_3distributions = np.zeros((26,26))\n",
    "\n",
    "    for i in range(26):\n",
    "        for j in range(26):\n",
    "            if grf_array[i][j] <= threshold1:\n",
    "                resultant_array_3distributions[i][j] = 0\n",
    "            elif threshold1 < grf_array[i][j] <= threshold2:\n",
    "                resultant_array_3distributions[i][j] = 0.5\n",
    "            else:\n",
    "                resultant_array_3distributions[i][j] = 1\n",
    "\n",
    "    # Create a custom color map for the final visualization\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"black\", \"purple\", \"yellow\"])\n",
    "\n",
    "    # Plot the resulting array\n",
    "    plt.imshow(resultant_array_3distributions, cmap=cmap)\n",
    "    plt.colorbar()  # To show the color scale\n",
    "    plt.savefig(\"data/result_{}.png\".format(num))\n",
    "    plt.close()\n",
    "    # plt.show()\n",
    "    return resultant_array_3distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_array_2bingham_distributions(num):\n",
    "    # structured field with a size of 100x100 and a grid-size of 1x1\n",
    "    x = y = range(26)\n",
    "\n",
    "    model = Gaussian(dim=2, var=1, len_scale=500)\n",
    "    srf = SRF(model)\n",
    "    grf_array = srf.structured([x, y])\n",
    "    # srf1.plot()\n",
    "    # plt.imshow(grf_array)\n",
    "    # plt.colorbar()  # To show the color scale\n",
    "    # plt.savefig(\"data/grfplot_{}.png\".format(num))\n",
    "    # plt.show()\n",
    "\n",
    "    # Dynamically calculate thresholds based on percentiles\n",
    "    percentile = np.random.uniform(20, 80)\n",
    "    threshold = np.percentile(grf_array, percentile)\n",
    "    minimum1 = grf_array.min()\n",
    "    maximum1 = grf_array.max()\n",
    "\n",
    "    # print(f\"Minimum: {minimum1}\")\n",
    "    # print(f\"Maximum: {maximum1}\")\n",
    "    print(f\"30th Percentile (Dynamic): {percentile}\")\n",
    "\n",
    "    resultant_array_2distributions = np.zeros((26,26))\n",
    "\n",
    "    for i in range(26):\n",
    "        for j in range(26):\n",
    "            if grf_array[i][j] <= threshold:\n",
    "                resultant_array_2distributions[i][j] = 0\n",
    "            else:\n",
    "                resultant_array_2distributions[i][j] = 1\n",
    "\n",
    "    # Create a custom color map for the final visualization\n",
    "    cmap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"black\", \"yellow\"])\n",
    "\n",
    "    # Plot the resulting array\n",
    "    plt.imshow(resultant_array_2distributions, cmap=cmap)\n",
    "    plt.colorbar()  # To show the color scale\n",
    "    plt.savefig(\"data/result_{}.png\".format(num))\n",
    "    # plt.show()\n",
    "    return resultant_array_2distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background(internal_loop):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, internal_loop, *args, **kwargs)\n",
    "    return wrapped\n",
    "\n",
    "class AII_model:\n",
    "    def __init__(self, array, eta1, kappa1, mu_phi1, mu_theta1, eta2, kappa2, mu_phi2, mu_theta2, eta3, kappa3, mu_phi3, mu_theta3):\n",
    "        # eta, kappa = 0.25 , 0.05\n",
    "        self.condRef = 8.7e5\n",
    "        self.sigxx = 8.97e5\n",
    "        self.sigzz = 8.43e5\n",
    "        self.coil_rad_x = 2.1509e6\n",
    "        self.coil_rad_y = 2.1509e6\n",
    "        self.eta1 = eta1\n",
    "        self.kappa1 = kappa1\n",
    "        self.mu_phi1 = mu_phi1\n",
    "        self.mu_theta1 = mu_theta1\n",
    "        self.eta2 = eta2\n",
    "        self.kappa2 = kappa2\n",
    "        self.mu_phi2 = mu_phi2\n",
    "        self.mu_theta2 = mu_theta2\n",
    "        self.eta3 = eta3\n",
    "        self.kappa3 = kappa3\n",
    "        self.mu_phi3 = mu_phi3\n",
    "        self.mu_theta3 = mu_theta3\n",
    "        self.data_to_append = []\n",
    "        self.phi_theta_sigma_data = {}\n",
    "        self.array = array\n",
    "        self.V1 , self.V2, self.V3 , self.lambda1, self.lambda2, self.lambda3, \\\n",
    "        self.V21 , self.V22, self.V23 , self.lambda21, self.lambda22, self.lambda23, \\\n",
    "        self.V31 , self.V32, self.V33, self.lambda31, self.lambda32, self.lambda33 = self.compute_bingham_distributions()\n",
    "        self.pdf_value = self.calculate_mx_value()\n",
    "        self.candidates = []\n",
    "        self.eulerangles = []\n",
    "        self.microstructure_list = {}\n",
    "        self.number_of_microstructures = 1\n",
    "\n",
    "    async def async_init(self):\n",
    "        await self.run_simulation()\n",
    "\n",
    "    def compute_bingham_distributions(self):\n",
    "        V1 = np.array([\n",
    "            np.cos(self.mu_theta1/2)*np.cos(self.mu_phi1/2),\n",
    "            -1*np.sin(self.mu_theta1/2)*np.cos(self.mu_phi1/2),\n",
    "            -1*np.sin(self.mu_theta1/2)*np.sin(self.mu_phi1/2),\n",
    "            -1*np.cos(self.mu_theta1/2)*np.sin(self.mu_phi1/2)\n",
    "        ])\n",
    "        V2 = np.array([\n",
    "            -0.5 * np.cos(self.mu_theta1/2) * np.sin(self.mu_phi1 / 2),\n",
    "            0.5 * np.sin(self.mu_theta1/2) * np.sin(self.mu_phi1 / 2),\n",
    "            -0.5 * np.sin(self.mu_theta1/2) * np.cos(self.mu_phi1 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta1/2) * np.cos(self.mu_phi1 / 2)\n",
    "        ])\n",
    "        V3 = np.array([\n",
    "            -0.5 * np.sin(self.mu_theta1/2) * np.cos(self.mu_phi1 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta1/2) * np.cos(self.mu_phi1 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta1/2) * np.sin(self.mu_phi1 / 2),\n",
    "            0.5 * np.sin(self.mu_theta1/2) * np.sin(self.mu_phi1 / 2)\n",
    "        ])\n",
    "        l1 = -0.5\n",
    "        l2 = l1 / self.eta1\n",
    "        l3 = l2 / self.kappa1\n",
    "        V21 = np.array([\n",
    "            np.cos(self.mu_theta2/2)*np.cos(self.mu_phi2/2),\n",
    "            -1*np.sin(self.mu_theta2/2)*np.cos(self.mu_phi2/2),\n",
    "            -1*np.sin(self.mu_theta2/2)*np.sin(self.mu_phi2/2),\n",
    "            -1*np.cos(self.mu_theta2/2)*np.sin(self.mu_phi2/2)\n",
    "        ])\n",
    "        V22 = np.array([\n",
    "            -0.5 * np.cos(self.mu_theta2/2) * np.sin(self.mu_phi2 / 2),\n",
    "            0.5 * np.sin(self.mu_theta2/2) * np.sin(self.mu_phi2 / 2),\n",
    "            -0.5 * np.sin(self.mu_theta2/2) * np.cos(self.mu_phi2 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta2/2) * np.cos(self.mu_phi2 / 2)\n",
    "        ])\n",
    "        V23 = np.array([\n",
    "            -0.5 * np.sin(self.mu_theta2/2) * np.cos(self.mu_phi2 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta2/2) * np.cos(self.mu_phi2 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta2/2) * np.sin(self.mu_phi2 / 2),\n",
    "            0.5 * np.sin(self.mu_theta2/2) * np.sin(self.mu_phi2 / 2)\n",
    "        ])\n",
    "        l21 = -0.5\n",
    "        l22 = l21 / self.eta2\n",
    "        l23 = l22 / self.kappa2\n",
    "        V31 = np.array([\n",
    "            np.cos(self.mu_theta3/2)*np.cos(self.mu_phi3/2),\n",
    "            -1*np.sin(self.mu_theta3/2)*np.cos(self.mu_phi3/2),\n",
    "            -1*np.sin(self.mu_theta3/2)*np.sin(self.mu_phi3/2),\n",
    "            -1*np.cos(self.mu_theta3/2)*np.sin(self.mu_phi3/2)\n",
    "        ])\n",
    "        V32 = np.array([\n",
    "            -0.5 * np.cos(self.mu_theta3/2) * np.sin(self.mu_phi3 / 2),\n",
    "            0.5 * np.sin(self.mu_theta3/2) * np.sin(self.mu_phi3 / 2),\n",
    "            -0.5 * np.sin(self.mu_theta3/2) * np.cos(self.mu_phi3 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta3/2) * np.cos(self.mu_phi3 / 2)\n",
    "        ])\n",
    "        V33 = np.array([\n",
    "            -0.5 * np.sin(self.mu_theta3/2) * np.cos(self.mu_phi3 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta3/2) * np.cos(self.mu_phi3 / 2),\n",
    "            -0.5 * np.cos(self.mu_theta3/2) * np.sin(self.mu_phi3 / 2),\n",
    "            0.5 * np.sin(self.mu_theta3/2) * np.sin(self.mu_phi3 / 2)\n",
    "        ])\n",
    "        l31 = -0.5\n",
    "        l32 = l1 / self.eta3\n",
    "        l33 = l2 / self.kappa3\n",
    "        \n",
    "        return V1 , V2 , V3 , l1 , l2 , l3 , V21 , V22 , V23 , l21 , l22 , l23 , V31 , V32 , V33 , l31 , l32 , l33 \n",
    "\n",
    "    def pi1_x(self, x):\n",
    "        term1 = self.lambda1 * (np.dot(self.V1.T, x)) ** 2\n",
    "        term2 = self.lambda2 * (np.dot(self.V2.T, x)) ** 2\n",
    "        term3 = self.lambda3 * (np.dot(self.V3.T, x)) ** 2\n",
    "\n",
    "        sum_terms = term1 + term2 + term3\n",
    "\n",
    "        pi_x_value = np.exp(sum_terms)\n",
    "        return pi_x_value\n",
    "    \n",
    "    def pi2_x(self, x):\n",
    "        term1 = self.lambda21 * (np.dot(self.V21.T, x)) ** 2\n",
    "        term2 = self.lambda22 * (np.dot(self.V22.T, x)) ** 2\n",
    "        term3 = self.lambda23 * (np.dot(self.V23.T, x)) ** 2\n",
    "\n",
    "        sum_terms = term1 + term2 + term3\n",
    "\n",
    "        pi_x_value = np.exp(sum_terms)\n",
    "        return pi_x_value\n",
    "    \n",
    "    def pi3_x(self, x):\n",
    "        term1 = self.lambda31 * (np.dot(self.V31.T, x)) ** 2\n",
    "        term2 = self.lambda32 * (np.dot(self.V32.T, x)) ** 2\n",
    "        term3 = self.lambda33 * (np.dot(self.V33.T, x)) ** 2\n",
    "\n",
    "        sum_terms = term1 + term2 + term3\n",
    "\n",
    "        pi_x_value = np.exp(sum_terms)\n",
    "        return pi_x_value\n",
    "    \n",
    "    def calculate_mx_value(self):\n",
    "        return 1\n",
    "            \n",
    "    def rununtiltrue(self, number):\n",
    "        while True:\n",
    "            x_candidate = self.generaterandomquaternion()\n",
    "            if number==0:\n",
    "                f_candidate = self.pi1_x(x_candidate)\n",
    "            elif number==0.5:\n",
    "                f_candidate = self.pi2_x(x_candidate)\n",
    "            elif number==1:\n",
    "                f_candidate = self.pi3_x(x_candidate)\n",
    "            alpha = f_candidate / self.pdf_value\n",
    "            if alpha >= 0.98:\n",
    "                return x_candidate\n",
    "\n",
    "    def generaterandomquaternion(self):\n",
    "        # Sample three uniform random variables\n",
    "        u1, u2, u3 = np.random.rand(3)\n",
    "\n",
    "        # Compute the quaternion components\n",
    "        q = np.array([\n",
    "            np.sqrt(1-u1) * np.sin(2*np.pi*u2),\n",
    "            np.sqrt(1-u1) * np.cos(2*np.pi*u2),\n",
    "            np.sqrt(u1) * np.sin(2*np.pi*u3),\n",
    "            np.sqrt(u1) * np.cos(2*np.pi*u3)\n",
    "        ])\n",
    "        return q\n",
    "    \n",
    "    @staticmethod\n",
    "    def quaternion_to_rotation_matrix(q):\n",
    "        # Compute the associated rotation matrix from the quaternion\n",
    "        R = np.array([\n",
    "            [np.square(q[0]) + np.square(q[1]) - np.square(q[2]) - np.square(q[3]), 2*(q[1]*q[2] + q[0]*q[3]), 2*(q[1]*q[3] - q[0]*q[2])],\n",
    "            [2*(q[1]*q[2] - q[0]*q[3]), np.square(q[0]) - np.square(q[1]) + np.square(q[2]) - np.square(q[3]), 2*(q[3]*q[2] + q[0]*q[1])],\n",
    "            [2*(q[3]*q[1] + q[0]*q[2]), 2*(q[3]*q[2] - q[0]*q[1]), np.square(q[0]) - np.square(q[1]) - np.square(q[2]) + np.square(q[3])]\n",
    "        ])\n",
    "        return R\n",
    "    \n",
    "    @staticmethod\n",
    "    def rotation_matrix_to_euler_angles(R):\n",
    "        second_angle = np.arccos(R[2][2])\n",
    "        if second_angle > 0:\n",
    "            first_angle = np.arctan2(R[2][0], -R[2][1])\n",
    "            third_angle = np.arctan2(R[0][2], R[1][2])\n",
    "        elif second_angle == 0:\n",
    "            first_angle = np.arctan2(R[0][1], R[0][0])\n",
    "            third_angle = 0\n",
    "        return first_angle, second_angle, third_angle\n",
    "\n",
    "    @staticmethod\n",
    "    def quaternion_angular_difference(q1, q2):\n",
    "        # Ensure the quaternions are normalized\n",
    "        q1 = q1 / np.linalg.norm(q1)\n",
    "        q2 = q2 / np.linalg.norm(q2)\n",
    "        # Calculate the dot product between the two quaternions\n",
    "        dot_product = np.dot(q1, q2)\n",
    "        # Clamp the dot product to avoid numerical issues\n",
    "        dot_product = np.clip(dot_product, -1.0, 1.0)\n",
    "        # Calculate the angular difference in radians\n",
    "        angle = 2 * np.arccos(dot_product)\n",
    "        # Convert radians to degrees\n",
    "        return angle\n",
    "    \n",
    "    async def process_element(self, i, j, number):\n",
    "        # x_candidate = []\n",
    "        if number==0:\n",
    "            x_candidate = self.rununtiltrue(number)\n",
    "        elif number==0.5:\n",
    "            x_candidate = self.rununtiltrue(number)\n",
    "        elif number==1:\n",
    "            x_candidate = self.rununtiltrue(number)\n",
    "        self.candidates.append(x_candidate)\n",
    "        angle = self.rotation_matrix_to_euler_angles(self.quaternion_to_rotation_matrix(x_candidate))\n",
    "        first, second, third = angle\n",
    "        self.eulerangles.append(angle)\n",
    "        self.data_to_append.append((i, j, first, second, third))\n",
    "            \n",
    "    async def process_microstructure(self, val):\n",
    "        \"\"\"Process each microstructure in parallel.\"\"\"\n",
    "        tasks = []\n",
    "        for i in range(26):\n",
    "            for j in range(26):\n",
    "                if self.array[i][j]==0:\n",
    "                    tasks.append(self.process_element(i, j, 0))\n",
    "                elif self.array[i][j]==0.5:\n",
    "                    tasks.append(self.process_element(i, j, 0.5))\n",
    "                elif self.array[i][j]==1:\n",
    "                    tasks.append(self.process_element(i, j, 1))\n",
    "        await asyncio.gather(*tasks)\n",
    "        self.data_to_append.sort(key=lambda x: (x[0], x[1]))\n",
    "        self.microstructure_list[val] = self.data_to_append\n",
    "#         print(self.data_to_append)\n",
    "        # print(f\"Printing for {val} microstructure\")\n",
    "    \n",
    "    async def run_simulation(self):\n",
    "        \"\"\"Parallelize the outer loop using asyncio tasks.\"\"\"\n",
    "        start_time = time.time()\n",
    "        outer_tasks = [self.process_microstructure(val) for val in range(1, self.number_of_microstructures+1)]\n",
    "        await asyncio.gather(*outer_tasks)\n",
    "        end_time = time.time() - start_time\n",
    "        print(f\"Time taken by run_simulation: {end_time} seconds\")\n",
    "\n",
    "    def write_data_to_new_file(self,file_path):\n",
    "        # Check if the file exists, delete it if it does\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "        # Open the file in append mode ('a') or create it if it doesn't exist ('a+')\n",
    "        with open(file_path, 'a') as file:\n",
    "            # Append each line of data to the file\n",
    "            for line in self.data_to_append[:]:\n",
    "                file.write(' '.join(map(str, line)) + '\\n')  # Add a newline character to separate entries\n",
    "                    \n",
    "    def write_data_to_new_file2(self, file_path):\n",
    "        # Check if the file exists, delete it if it does\n",
    "        if os.path.exists(file_path):\n",
    "            os.remove(file_path)\n",
    "\n",
    "        # Open the file in write mode ('w') to create or overwrite the file\n",
    "        with open(file_path, 'w') as file:\n",
    "            # Reshape the 1x676 data into 26x26 format and write each row to a new line\n",
    "            for i in range(26):\n",
    "                row_data = self.data_to_append[i*26:(i+1)*26]  # Get the data for the current row\n",
    "                file.write(' '.join(map(str, row_data)) + '\\n')  # Write the row to the file\n",
    "\n",
    "    def scan_operation(self): \n",
    "        microstructure = self.microstructure_list[1]\n",
    "        # Extracting X, Y, phi, and theta values from each microstructure\n",
    "        X = np.array([tup[0] for tup in microstructure])      # * (6176/25) + 8\n",
    "        X = X.reshape((26, 26)).T\n",
    "        X = np.stack((X, X), axis=2)\n",
    "\n",
    "        Y = np.array([tup[1] for tup in microstructure])      #* (6312/25) + 8\n",
    "        Y = Y.reshape((26, 26)).T\n",
    "        Y = np.stack((Y, Y), axis=2)\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "            \n",
    "        for val, microstructure in self.microstructure_list.items():\n",
    "\n",
    "            phi = np.array([tup[2] for tup in microstructure])\n",
    "            phi = phi.reshape((26, 26)).T\n",
    "            phi = np.stack((phi, phi), axis=2)\n",
    "            cphi = np.cos(phi)\n",
    "            sphi = np.sin(phi)\n",
    "\n",
    "            theta = np.array([tup[3] for tup in microstructure])\n",
    "            theta = theta.reshape((26, 26)).T\n",
    "            theta = np.stack((theta, theta), axis=2)\n",
    "            stheta = np.sin(theta)\n",
    "\n",
    "            # Optionally, you can store these processed arrays in a dictionary if needed\n",
    "            self.microstructure_list[val] = {\n",
    "                'cphi': cphi,\n",
    "                'sphi': sphi,\n",
    "                'stheta': stheta,\n",
    "                'microstructure': microstructure\n",
    "            }\n",
    "        \n",
    "        scanDims = {'scanStart': np.array([0, 0, 0]), 'scanLength': np.array([5, 5, 5]), 'scanStep': np.array([0.2, 0.2, 0.2])}\n",
    "\n",
    "        #scanDims['scanStart'] *= 1000\n",
    "        #scanDims['scanLength'] *= 1000\n",
    "        #scanDims['scanStep'] *= 1000\n",
    "\n",
    "        # Calculate number of points in each dimension\n",
    "        numXPoints = int(scanDims['scanLength'][0] / scanDims['scanStep'][0]) + 1\n",
    "        numYPoints = int(scanDims['scanLength'][1] / scanDims['scanStep'][1]) + 1\n",
    "\n",
    "        scanDims['scanStep'] = [1,1,1];\n",
    "        \n",
    "        # Set up the scan structure\n",
    "        scan = np.zeros((numXPoints, numYPoints), dtype=object)\n",
    "        for ixpos in range(numXPoints):\n",
    "            for iypos in range(numYPoints):\n",
    "                scan[iypos, ixpos] = {\n",
    "                    'num': 0,\n",
    "                    'pos': [\n",
    "                        scanDims['scanStart'][0] + scanDims['scanStep'][0] * ixpos,\n",
    "                        scanDims['scanStart'][1] + scanDims['scanStep'][1] * iypos\n",
    "                    ],\n",
    "                    'area': [],\n",
    "                    'total': 0\n",
    "                }\n",
    "\n",
    "        Exs = np.load('Exs_26_26_updated_iterations.npy')\n",
    "        Eys = np.load('Eys_26_26_updated_iterations.npy')\n",
    "\n",
    "        mul = np.zeros(scan.shape, dtype=np.complex128)\n",
    "\n",
    "        for val, microstructure_data in self.microstructure_list.items():\n",
    "            # Initialize scanPoint\n",
    "            scanPoint = 0\n",
    "\n",
    "            # Initialize ectScan with the same structure as scan but with all elements set to zero\n",
    "            ectScan = {\n",
    "                'val': val,\n",
    "                'XD': np.zeros(scan.shape, dtype=float),\n",
    "                'YD': np.zeros(scan.shape, dtype=float),\n",
    "                'zl': np.zeros(scan.shape, dtype=np.complex128),\n",
    "                'Xsub_slice': np.empty(scan.shape, dtype=object),  \n",
    "                'Ysub_slice': np.empty(scan.shape, dtype=object),  \n",
    "                'Zsub_slice': np.empty(scan.shape, dtype=object)\n",
    "            }\n",
    "\n",
    "            sphi_sub = microstructure_data['sphi']\n",
    "            stheta_sub = microstructure_data['stheta']\n",
    "            cphi_sub = microstructure_data['cphi']\n",
    "\n",
    "            # Compute sigma values once per microstructure\n",
    "            sigma_11 = self.sigxx + (self.sigzz - self.sigxx) * sphi_sub ** 2 * stheta_sub ** 2\n",
    "            sigma_12 = ((self.sigxx - self.sigzz) * (sphi_sub * cphi_sub * (stheta_sub ** 2))) / 2\n",
    "            sigma_22 = self.sigxx + ((self.sigzz - self.sigxx) * (stheta_sub ** 2)) + ((self.sigxx - self.sigzz) * (sphi_sub ** 2) * (stheta_sub ** 2))\n",
    "\n",
    "            numX, numY = scan.shape\n",
    "            real_partf_list = np.empty(scan.shape, dtype=object)\n",
    "            imag_partf_list = np.empty(scan.shape, dtype=object)\n",
    "            for ix in range(numX):\n",
    "                for iy in range(numY):\n",
    "\n",
    "                    X = self.X\n",
    "                    Y = self.Y\n",
    "                    x = np.squeeze(X[0, :, 0])\n",
    "                    y = np.squeeze(Y[:, 0, 0])\n",
    "\n",
    "                    # Min and max distances from coil to position in x and y directions\n",
    "                    #cx_lim_low = scan[ix, iy]['pos'][0] - self.coil_rad_x\n",
    "                    #cx_lim_hi = scan[ix, iy]['pos'][0] + self.coil_rad_x\n",
    "                    #cy_lim_low = scan[ix, iy]['pos'][1] - self.coil_rad_y\n",
    "                    #cy_lim_hi = scan[ix, iy]['pos'][1] + self.coil_rad_y\n",
    "\n",
    "                    # Find the indices for x and y using numpy\n",
    "                    #lowIndX = np.argmax(x >= cx_lim_low)\n",
    "                    #highIndX = np.argmax(x >= cx_lim_hi) - 1 if np.any(x >= cx_lim_hi) else len(x) - 1\n",
    "                    #lowIndY = np.argmax(y >= cy_lim_low)\n",
    "                    #highIndY = np.argmax(y >= cy_lim_hi) - 1 if np.any(y >= cy_lim_hi) else len(y) - 1\n",
    "                    #lowIndZ = 0\n",
    "                    #highIndZ = 1\n",
    "\n",
    "                    # Extract subarrays for X, Y, Z\n",
    "\n",
    "                    #Xsub = X[lowIndY:highIndY+1, lowIndX:highIndX+1, lowIndZ:highIndZ+1] - scan[ix, iy]['pos'][0]\n",
    "\n",
    "                    #Ysub = Y[lowIndY:highIndY+1, lowIndX:highIndX+1, lowIndZ:highIndZ+1] - scan[ix, iy]['pos'][1]\n",
    "\n",
    "                    Xsub = X - scan[ix, iy]['pos'][0]\n",
    "                    Ysub = Y - scan[ix, iy]['pos'][1]\n",
    "                    array1 = np.ones((X.shape[0], X.shape[1], 1)) * 8\n",
    "                    array2 = np.ones((X.shape[0], X.shape[1], 1)) * 72\n",
    "\n",
    "                    # Stack these arrays along the third dimension\n",
    "                    Zsub = np.concatenate((array1, array2), axis=2)\n",
    "                    # Ex = griddata(points, vals_x, (Xsub, Ysub, Zsub) , method='nearest')\n",
    "                    # Ey = griddata(points, vals_y, (Xsub, Ysub, Zsub) , method='nearest')\n",
    "\n",
    "                    Ex = Exs[scanPoint]   \n",
    "                    Ey = Eys[scanPoint]\n",
    "\n",
    "                    # Components of the approximate impedance integral (AII)\n",
    "                    f1 = Ex ** 2 * (self.condRef - sigma_11)\n",
    "                    f2 = -2 * Ex * Ey * sigma_12\n",
    "                    f3 = Ey ** 2 * (self.condRef - sigma_22)\n",
    "                    f = f1 + f2 + f3\n",
    "                    real_partf_list[iy, ix] = np.real(f)\n",
    "                    imag_partf_list[iy, ix] = np.imag(f)\n",
    "                    \n",
    "                    Xsub_slice = (np.squeeze(Xsub[0, :, 0]) / 1e6)\n",
    "                    Ysub_slice = (np.squeeze(Ysub[:, 0, 0]) / 1e6)\n",
    "                    Zsub_slice = (np.squeeze(Zsub[0, 0, :]) / 1e6)\n",
    "                    \n",
    "#                     Xsub_slice = np.squeeze(Xsub[0, :, 0])\n",
    "#                     Ysub_slice = np.squeeze(Ysub[:, 0, 0])\n",
    "#                     Zsub_slice = np.squeeze(Zsub[0, 0, :])\n",
    "                                  \n",
    "                    integral_inner = np.trapz(f, x=Xsub_slice, axis=1).reshape(26,1,2)\n",
    "                    integral_middle = np.trapz(integral_inner, x=Ysub_slice, axis=0).reshape(1,1,2)\n",
    "                    zl = np.trapz(integral_middle, x=Zsub_slice, axis=2)\n",
    "\n",
    "                    #ectScan['XD'][ix, iy] = scan[ix, iy]['pos'][0] / 1000  # Back to mm\n",
    "                    #ectScan['YD'][ix, iy] = scan[ix, iy]['pos'][1] / 1000  # Back to mm\n",
    "                    ectScan['Xsub_slice'][iy, ix] = Xsub_slice\n",
    "                    ectScan['Ysub_slice'][iy, ix] = Ysub_slice\n",
    "                    ectScan['Zsub_slice'][iy, ix] = Zsub_slice\n",
    "                    ectScan['zl'][iy, ix] = zl\n",
    "                    \n",
    "                    mul[iy, ix] += ectScan['zl'][iy, ix]\n",
    "                    \n",
    "                    scanPoint += 1\n",
    "            microstructure_data['ectScan'] = ectScan\n",
    "            microstructure_data['realpartlist'] = real_partf_list\n",
    "            microstructure_data['imagpartlist'] = imag_partf_list\n",
    "\n",
    "        mul = mul/self.number_of_microstructures\n",
    "\n",
    "        # Store the 'mul' result back in self if needed\n",
    "        self.mul = mul\n",
    "        return ectScan\n",
    "\n",
    "    def calculate_covariance_matrix(self):\n",
    "        num_microstructures = len(self.microstructure_list)\n",
    "        num_elements = 676  # 26 * 26\n",
    "        single_side = 26\n",
    "        # Initialize covariance matrices\n",
    "        gamma = np.zeros((num_elements, num_elements), dtype=np.complex128)\n",
    "        gamma_hat = np.zeros((num_elements, num_elements), dtype=float)\n",
    "        \n",
    "        for l in range(num_elements):\n",
    "            for k in range(l + 1):\n",
    "                sum_zl_product = 0\n",
    "                for val, microstructure_data in self.microstructure_list.items():\n",
    "                    ectScan = microstructure_data['ectScan']\n",
    "                    zl_flatten = ectScan['zl'].flatten()\n",
    "                    # Get zl for l and k\n",
    "                    zl_l = zl_flatten[l]\n",
    "                    zl_k = zl_flatten[k]\n",
    "\n",
    "                    sum_zl_product += zl_l * zl_k \n",
    "                    \n",
    "                gamma[l, k] = sum_zl_product / self.number_of_microstructures  - (self.mul.flat[l]*self.mul.flat[k])\n",
    "                gamma[k, l] = gamma[l, k]\n",
    "            \n",
    "        self.gamma = gamma\n",
    "        \n",
    "        for l in range(num_elements):  # num_elements is the size of the matrix\n",
    "            for k in range(l + 1):\n",
    "                sum_zlk_product = 0\n",
    "                sum_zkl_product = 0\n",
    "                for val, microstructure_data in self.microstructure_list.items():\n",
    "                    i, j = divmod(l, single_side)\n",
    "                    m, n = divmod(k, single_side)\n",
    "\n",
    "                    realpartl = microstructure_data['realpartlist'][i,j]\n",
    "                    imagpartl = microstructure_data['imagpartlist'][i,j]\n",
    "                    \n",
    "                    realpartk = microstructure_data['realpartlist'][m,n]\n",
    "                    imagpartk = microstructure_data['imagpartlist'][m,n]\n",
    "                    \n",
    "                    Xsub_slicel = microstructure_data['ectScan']['Xsub_slice'][i,j]\n",
    "                    Ysub_slicel = microstructure_data['ectScan']['Ysub_slice'][i,j]\n",
    "                    Zsub_slicel = microstructure_data['ectScan']['Zsub_slice'][i,j]\n",
    "                    \n",
    "                    Xsub_slicek = microstructure_data['ectScan']['Xsub_slice'][m,n]\n",
    "                    Ysub_slicek = microstructure_data['ectScan']['Ysub_slice'][m,n]\n",
    "                    Zsub_slicek = microstructure_data['ectScan']['Zsub_slice'][m,n]\n",
    "                    \n",
    "                    integral_inner_l_lk = np.trapz(realpartl, x=Xsub_slicel, axis=1).reshape(25,1,2)\n",
    "                    integral_middle_l_lk = np.trapz(integral_inner_l_lk, x=Ysub_slicel, axis=0).reshape(1,1,2)\n",
    "                    zlk_l = np.trapz(integral_middle_l_lk, x=Zsub_slicel, axis=2)\n",
    "\n",
    "                    integral_inner_k_lk = np.trapz(imagpartk, x=Xsub_slicek, axis=1).reshape(25,1,2)\n",
    "                    integral_middle_k_lk = np.trapz(integral_inner_k_lk, x=Ysub_slicek, axis=0).reshape(1,1,2)\n",
    "                    zlk_k = np.trapz(integral_middle_k_lk, x=Zsub_slicek, axis=2)\n",
    "\n",
    "                    integral_inner_k_kl = np.trapz(realpartk, x=Xsub_slicek, axis=1).reshape(25,1,2)\n",
    "                    integral_middle_k_kl = np.trapz(integral_inner_k_kl, x=Ysub_slicek, axis=0).reshape(1,1,2)\n",
    "                    zkl_k = np.trapz(integral_middle_k_kl, x=Zsub_slicek, axis=2)\n",
    "\n",
    "                    integral_inner_l_kl = np.trapz(imagpartl, x=Xsub_slicel, axis=1).reshape(25,1,2)\n",
    "                    integral_middle_l_kl = np.trapz(integral_inner_l_kl, x=Ysub_slicel, axis=0).reshape(1,1,2)\n",
    "                    zkl_l = np.trapz(integral_middle_l_kl, x=Zsub_slicel, axis=2)\n",
    "                    \n",
    "                    # Compute product and accumulate\n",
    "                    sum_zlk_product += zlk_l * zlk_k\n",
    "                    sum_zkl_product += zkl_l * zkl_k\n",
    "\n",
    "                # Calculate the average across all microstructures\n",
    "                gamma_hat[l, k] = sum_zlk_product / self.number_of_microstructures  - (np.real(self.mul.flat[l])*np.imag(self.mul.flat[k]))\n",
    "                gamma_hat[k, l] = sum_zkl_product / self.number_of_microstructures  - (np.imag(self.mul.flat[l])*np.real(self.mul.flat[k]))\n",
    "\n",
    "        self.gamma_hat = gamma_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some instances are generated by creating_array_2bingham_distributions function and some are generated by creating_array_3bingham_distributions function.\n",
    "# In the main code, I am using three numbers, 0, 0.5 and 1 and generating bingham distributions based on that.\n",
    "# (26, 26, 3) for input is basically three euler angles for 26*26 different pixels.\n",
    "# (26, 26, 3) for output is basically the real part of sctscan, the imaginary part of ectscan and 1.\n",
    "\n",
    "# Lists to store all input and output data\n",
    "# Create CSV writers for input and output .npy file paths\n",
    "with open('data/input_data_paths.csv', mode='w', newline='') as input_csv_file, \\\n",
    "     open('data/output_data_paths.csv', mode='w', newline='') as output_csv_file:\n",
    "\n",
    "    # Create CSV writers\n",
    "    input_writer = csv.writer(input_csv_file)\n",
    "    output_writer = csv.writer(output_csv_file)\n",
    "\n",
    "    # Write headers (optional)\n",
    "    input_writer.writerow(['input_data_path'])\n",
    "    output_writer.writerow(['output_data_path'])\n",
    "\n",
    "    input_data_2bingham_distributions = []\n",
    "    output_data_2bingham_distributions = []\n",
    "    for i in range(1,501):\n",
    "        data = creating_array_2bingham_distributions(i)\n",
    "        # Dynamically generate the parameters for AII_model\n",
    "        eta1 = np.random.uniform(0.18, 0.25)  # Varies from 0.15 to 0.26\n",
    "        kappa1 = np.random.uniform(0.02, 0.1)  # Varies from 0.02 to 0.1\n",
    "        mu_phi1 = np.random.uniform(0, np.pi)  # Varies from 0 to pi\n",
    "        mu_theta1 = np.random.uniform(0, np.pi/2)  # Varies from 0 to pi/2\n",
    "\n",
    "        eta2 = np.random.uniform(0.18, 0.25)  # Varies from 0.15 to 0.26\n",
    "        kappa2 = np.random.uniform(0.02, 0.1)  # Varies from 0.02 to 0.1\n",
    "        mu_phi2 = np.random.uniform(0, np.pi)  # Varies from 0 to pi\n",
    "        mu_theta2 = np.random.uniform(0, np.pi/2)  # Varies from 0 to pi/2\n",
    "\n",
    "        eta3 = np.random.uniform(0.18, 0.25)  # Varies from 0.15 to 0.26\n",
    "        kappa3 = np.random.uniform(0.02, 0.1)  # Varies from 0.02 to 0.1\n",
    "        mu_phi3 = np.random.uniform(0, np.pi)  # Varies from 0 to pi\n",
    "        mu_theta3 = np.random.uniform(0, np.pi/2)  # Varies from 0 to pi/2\n",
    "\n",
    "        aiimodel = AII_model(data, eta1, kappa1, mu_phi1, mu_theta1, eta2, kappa2, mu_phi2, mu_theta2, eta3, kappa3, mu_phi3, mu_theta3)\n",
    "        await aiimodel.async_init()\n",
    "        inputdataarray = np.array([entry[2:] for entry in aiimodel.data_to_append])\n",
    "        inputdataarray = inputdataarray.reshape(26, 26, 3)\n",
    "        # aiimodel.write_data_to_new_file('data2.txt')\n",
    "        ectScan = aiimodel.scan_operation()\n",
    "        plt.close()\n",
    "        plt.imshow(np.real(ectScan['zl']))\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"data/ectscan_real_{}.png\".format(i))\n",
    "        plt.close()\n",
    "        plt.imshow(np.imag(ectScan['zl']))\n",
    "        plt.colorbar()\n",
    "        plt.savefig(\"data/ectscan_imag_{}.png\".format(i))\n",
    "        plt.close()\n",
    "        outputdataarray = np.array([(np.real(ectScan['zl'][i, j]), np.imag(ectScan['zl'][i, j]), 1) for i in range(26) for j in range(26)])\n",
    "        outputdataarray = outputdataarray.reshape(26, 26, 3)\n",
    "        # Save inputdataarray and outputdataarray as .npy files\n",
    "        input_file_path = f\"data/inputdataarray_{i}.npy\"\n",
    "        output_file_path = f\"data/outputdataarray_{i}.npy\"\n",
    "        txt_file_path = f\"data/data_{i}.txt\"\n",
    "        aiimodel.write_data_to_new_file(txt_file_path)\n",
    "        np.save(input_file_path, inputdataarray)\n",
    "        np.save(output_file_path, outputdataarray)\n",
    "\n",
    "        # Append input and output data to the lists\n",
    "        input_data_2bingham_distributions.append(inputdataarray)\n",
    "        output_data_2bingham_distributions.append(outputdataarray)\n",
    "        \n",
    "        # Write file paths to the CSV files\n",
    "        input_writer.writerow([input_file_path])\n",
    "        output_writer.writerow([output_file_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
